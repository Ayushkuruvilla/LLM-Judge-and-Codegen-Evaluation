{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# uncomment below if not installed yet\n",
    "# !pip install code-bert-score\n",
    "# !pip install nltk rouge-score "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T13:15:47.662299500Z",
     "start_time": "2025-01-20T13:15:44.194535700Z"
    }
   },
   "id": "3fc7e06bb56e803"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-19T23:46:47.899314Z",
     "start_time": "2025-01-19T23:44:06.193851800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "\n",
      "Processing for model output gemini-1.5...\n",
      "\n",
      "Computing BLEU score for task: HumanEval/0\n",
      "BLEU score: 0.27048170758554296\n",
      "\n",
      "Computing BLEU score for task: HumanEval/1\n",
      "BLEU score: 0.04739507532387779\n",
      "\n",
      "Computing BLEU score for task: HumanEval/2\n",
      "BLEU score: 1.0\n",
      "\n",
      "Computing BLEU score for task: HumanEval/3\n",
      "BLEU score: 0.6031612036218008\n",
      "\n",
      "Computing BLEU score for task: HumanEval/4\n",
      "BLEU score: 0.14023424042019694\n",
      "\n",
      "Computing BLEU score for task: HumanEval/5\n",
      "BLEU score: 0.10802314890908067\n",
      "\n",
      "Computing BLEU score for task: HumanEval/6\n",
      "BLEU score: 0.08806842539359157\n",
      "\n",
      "Computing BLEU score for task: HumanEval/7\n",
      "BLEU score: 0.03342866121562732\n",
      "\n",
      "Computing BLEU score for task: HumanEval/8\n",
      "BLEU score: 0.21223633441554032\n",
      "\n",
      "Computing BLEU score for task: HumanEval/9\n",
      "BLEU score: 0.011433361115787456\n",
      "\n",
      "Computing BLEU score for task: HumanEval/10\n",
      "BLEU score: 0.25590356077469273\n",
      "\n",
      "Computing BLEU score for task: HumanEval/11\n",
      "BLEU score: 0.03102878467054691\n",
      "\n",
      "Computing BLEU score for task: HumanEval/12\n",
      "BLEU score: 0.23477883426250248\n",
      "\n",
      "Computing BLEU score for task: HumanEval/13\n",
      "BLEU score: 0.02221613141830968\n",
      "\n",
      "Computing BLEU score for task: HumanEval/14\n",
      "BLEU score: 0.08737167851715875\n",
      "\n",
      "Computing BLEU score for task: HumanEval/15\n",
      "BLEU score: 0.016891032976324306\n",
      "\n",
      "Computing BLEU score for task: HumanEval/16\n",
      "BLEU score: 0.021105340631872645\n",
      "\n",
      "Computing BLEU score for task: HumanEval/17\n",
      "BLEU score: 0.05601907817995057\n",
      "\n",
      "Computing BLEU score for task: HumanEval/18\n",
      "BLEU score: 0.1361658548186748\n",
      "\n",
      "Computing BLEU score for task: HumanEval/19\n",
      "BLEU score: 0.40376704816991255\n",
      "\n",
      "Computing BLEU score for task: HumanEval/20\n",
      "BLEU score: 0.14227980900528808\n",
      "\n",
      "Computing BLEU score for task: HumanEval/21\n",
      "BLEU score: 0.005697859151313652\n",
      "\n",
      "Computing BLEU score for task: HumanEval/22\n",
      "BLEU score: 0.0072658577559704465\n",
      "\n",
      "Computing BLEU score for task: HumanEval/23\n",
      "BLEU score: 0.017033186037639283\n",
      "\n",
      "Computing BLEU score for task: HumanEval/24\n",
      "BLEU score: 0.25960543805779895\n",
      "\n",
      "Computing BLEU score for task: HumanEval/25\n",
      "BLEU score: 0.22353037537016948\n",
      "\n",
      "Computing BLEU score for task: HumanEval/26\n",
      "BLEU score: 0.055177848898164926\n",
      "\n",
      "Computing BLEU score for task: HumanEval/27\n",
      "BLEU score: 0.006032401726201458\n",
      "\n",
      "Computing BLEU score for task: HumanEval/28\n",
      "BLEU score: 0.017033186037639283\n",
      "\n",
      "Computing BLEU score for task: HumanEval/29\n",
      "BLEU score: 0.017033186037639283\n",
      "\n",
      "Computing BLEU score for task: HumanEval/30\n",
      "BLEU score: 0.0169861974906263\n",
      "\n",
      "Computing BLEU score for task: HumanEval/31\n",
      "BLEU score: 0.2068764954672419\n",
      "\n",
      "Computing BLEU score for task: HumanEval/32\n",
      "BLEU score: 0.022479153118513083\n",
      "\n",
      "Computing BLEU score for task: HumanEval/33\n",
      "BLEU score: 0.1894020890042567\n",
      "\n",
      "Computing BLEU score for task: HumanEval/34\n",
      "BLEU score: 0.1495348781221221\n",
      "\n",
      "Computing BLEU score for task: HumanEval/35\n",
      "BLEU score: 0.0072658577559704465\n",
      "\n",
      "Computing BLEU score for task: HumanEval/36\n",
      "BLEU score: 0.5158015768242247\n",
      "\n",
      "Computing BLEU score for task: HumanEval/37\n",
      "BLEU score: 0.025863319306085313\n",
      "\n",
      "Computing BLEU score for task: HumanEval/38\n",
      "BLEU score: 0.8702397637697912\n",
      "\n",
      "Computing BLEU score for task: HumanEval/39\n",
      "BLEU score: 0.11095043671245404\n",
      "\n",
      "Computing BLEU score for task: HumanEval/40\n",
      "BLEU score: 0.3230444090662658\n",
      "\n",
      "Computing BLEU score for task: HumanEval/41\n",
      "BLEU score: 0.011231940108313073\n",
      "\n",
      "Computing BLEU score for task: HumanEval/42\n",
      "BLEU score: 1.0\n",
      "\n",
      "Computing BLEU score for task: HumanEval/43\n",
      "BLEU score: 0.030067609934128877\n",
      "\n",
      "Computing BLEU score for task: HumanEval/44\n",
      "BLEU score: 0.35630548449868954\n",
      "\n",
      "Computing BLEU score for task: HumanEval/45\n",
      "BLEU score: 0.10266900960803409\n",
      "\n",
      "Computing BLEU score for task: HumanEval/46\n",
      "BLEU score: 0.9551190479308641\n",
      "\n",
      "Computing BLEU score for task: HumanEval/47\n",
      "BLEU score: 0.06384875295507793\n",
      "\n",
      "Computing BLEU score for task: HumanEval/48\n",
      "BLEU score: 0.03303164318013808\n",
      "\n",
      "Computing BLEU score for task: HumanEval/49\n",
      "BLEU score: 0.3556537107066784\n",
      "\n",
      "Computing BLEU score for task: HumanEval/50\n",
      "BLEU score: 0\n",
      "\n",
      "Computing BLEU score for task: HumanEval/51\n",
      "BLEU score: 0.02253741272267485\n",
      "\n",
      "Computing BLEU score for task: HumanEval/52\n",
      "BLEU score: 0.022416933501922302\n",
      "\n",
      "Computing BLEU score for task: HumanEval/53\n",
      "BLEU score: 1.0\n",
      "\n",
      "Computing BLEU score for task: HumanEval/54\n",
      "BLEU score: 0.09554427922043669\n",
      "\n",
      "Computing BLEU score for task: HumanEval/55\n",
      "BLEU score: 0.3943996895930304\n",
      "\n",
      "Computing BLEU score for task: HumanEval/56\n",
      "BLEU score: 0.08078245916444435\n",
      "\n",
      "Computing BLEU score for task: HumanEval/57\n",
      "BLEU score: 0.4262815559749047\n",
      "\n",
      "Computing BLEU score for task: HumanEval/58\n",
      "BLEU score: 0.033031643180138064\n",
      "\n",
      "Computing BLEU score for task: HumanEval/59\n",
      "BLEU score: 0.05621071665433083\n",
      "\n",
      "Computing BLEU score for task: HumanEval/60\n",
      "BLEU score: 0.017395797375642234\n",
      "\n",
      "Computing BLEU score for task: HumanEval/61\n",
      "BLEU score: 0.16855632074966925\n",
      "\n",
      "Computing BLEU score for task: HumanEval/62\n",
      "BLEU score: 0.1487964117124549\n",
      "\n",
      "Computing BLEU score for task: HumanEval/63\n",
      "BLEU score: 0.8057137025938019\n",
      "\n",
      "Computing BLEU score for task: HumanEval/64\n",
      "BLEU score: 0.03551851328486764\n",
      "\n",
      "Computing BLEU score for task: HumanEval/65\n",
      "BLEU score: 0.23901565482017642\n",
      "\n",
      "Computing BLEU score for task: HumanEval/66\n",
      "BLEU score: 0.015276780223747026\n",
      "\n",
      "Computing BLEU score for task: HumanEval/67\n",
      "BLEU score: 0.034956162752843425\n",
      "\n",
      "Computing BLEU score for task: HumanEval/68\n",
      "BLEU score: 0.08000981634386346\n",
      "\n",
      "Computing BLEU score for task: HumanEval/69\n",
      "BLEU score: 0.03394854422852278\n",
      "\n",
      "Computing BLEU score for task: HumanEval/70\n",
      "BLEU score: 0.015890207245347555\n",
      "\n",
      "Computing BLEU score for task: HumanEval/71\n",
      "BLEU score: 0.10031191721760055\n",
      "\n",
      "Computing BLEU score for task: HumanEval/72\n",
      "BLEU score: 0.00898705062358146\n",
      "\n",
      "Computing BLEU score for task: HumanEval/73\n",
      "BLEU score: 0.28859523083492383\n",
      "\n",
      "Computing BLEU score for task: HumanEval/74\n",
      "BLEU score: 0.004520082205234763\n",
      "\n",
      "Computing BLEU score for task: HumanEval/75\n",
      "BLEU score: 0.16623373913368517\n",
      "\n",
      "Computing BLEU score for task: HumanEval/76\n",
      "BLEU score: 0.3430799506852667\n",
      "\n",
      "Computing BLEU score for task: HumanEval/77\n",
      "BLEU score: 0.005732293763835197\n",
      "\n",
      "Computing BLEU score for task: HumanEval/78\n",
      "BLEU score: 0.009410489957951634\n",
      "\n",
      "Computing BLEU score for task: HumanEval/79\n",
      "BLEU score: 0.036309066512747096\n",
      "\n",
      "Computing BLEU score for task: HumanEval/80\n",
      "BLEU score: 0.49809722097099235\n",
      "\n",
      "Computing BLEU score for task: HumanEval/81\n",
      "BLEU score: 0.018166146568060204\n",
      "\n",
      "Computing BLEU score for task: HumanEval/82\n",
      "BLEU score: 0.022379352592750163\n",
      "\n",
      "Computing BLEU score for task: HumanEval/83\n",
      "BLEU score: 0.18207052811092134\n",
      "\n",
      "Computing BLEU score for task: HumanEval/84\n",
      "BLEU score: 0.0067177027389942\n",
      "\n",
      "Computing BLEU score for task: HumanEval/85\n",
      "BLEU score: 0.3488783797973685\n",
      "\n",
      "Computing BLEU score for task: HumanEval/86\n",
      "BLEU score: 0.03440134693333791\n",
      "\n",
      "Computing BLEU score for task: HumanEval/87\n",
      "BLEU score: 0.1503400039489169\n",
      "\n",
      "Computing BLEU score for task: HumanEval/88\n",
      "BLEU score: 0.056066684111954215\n",
      "\n",
      "Computing BLEU score for task: HumanEval/89\n",
      "BLEU score: 0.022067713602073297\n",
      "\n",
      "Computing BLEU score for task: HumanEval/90\n",
      "BLEU score: 0.029883097780540872\n",
      "\n",
      "Computing BLEU score for task: HumanEval/91\n",
      "BLEU score: 0.0069228492760402315\n",
      "\n",
      "Computing BLEU score for task: HumanEval/92\n",
      "BLEU score: 0.02547134017057118\n",
      "\n",
      "Computing BLEU score for task: HumanEval/93\n",
      "BLEU score: 0.01064011414355274\n",
      "\n",
      "Computing BLEU score for task: HumanEval/94\n",
      "BLEU score: 0.010070319017053691\n",
      "\n",
      "Computing BLEU score for task: HumanEval/95\n",
      "BLEU score: 0.10917763738273828\n",
      "\n",
      "Computing BLEU score for task: HumanEval/96\n",
      "BLEU score: 0.10814410080481558\n",
      "\n",
      "Computing BLEU score for task: HumanEval/97\n",
      "BLEU score: 0.0169861974906263\n",
      "\n",
      "Computing BLEU score for task: HumanEval/98\n",
      "BLEU score: 0.35459684529390034\n",
      "\n",
      "Computing BLEU score for task: HumanEval/99\n",
      "BLEU score: 0.03183299787758537\n",
      "\n",
      "Computing BLEU score for task: HumanEval/100\n",
      "BLEU score: 0.18627639656696823\n",
      "\n",
      "Computing BLEU score for task: HumanEval/101\n",
      "BLEU score: 0.009109250643152446\n",
      "\n",
      "Computing BLEU score for task: HumanEval/102\n",
      "BLEU score: 0.14651860136741404\n",
      "\n",
      "Computing BLEU score for task: HumanEval/103\n",
      "BLEU score: 0.1572175759719851\n",
      "\n",
      "Computing BLEU score for task: HumanEval/104\n",
      "BLEU score: 0.09772992164303729\n",
      "\n",
      "Computing BLEU score for task: HumanEval/105\n",
      "BLEU score: 0.011660648851226097\n",
      "\n",
      "Computing BLEU score for task: HumanEval/106\n",
      "BLEU score: 0.1731049977855087\n",
      "\n",
      "Computing BLEU score for task: HumanEval/107\n",
      "BLEU score: 0.4194586780383904\n",
      "\n",
      "Computing BLEU score for task: HumanEval/108\n",
      "BLEU score: 0.007790345908226496\n",
      "\n",
      "Computing BLEU score for task: HumanEval/109\n",
      "BLEU score: 0.25557125511782486\n",
      "\n",
      "Computing BLEU score for task: HumanEval/110\n",
      "BLEU score: 0.037487570578416306\n",
      "\n",
      "Computing BLEU score for task: HumanEval/111\n",
      "BLEU score: 0.01667133532879895\n",
      "\n",
      "Computing BLEU score for task: HumanEval/112\n",
      "BLEU score: 0.02560744480557418\n",
      "\n",
      "Computing BLEU score for task: HumanEval/113\n",
      "BLEU score: 0.10540279742772932\n",
      "\n",
      "Computing BLEU score for task: HumanEval/114\n",
      "BLEU score: 0.023626998698784343\n",
      "\n",
      "Computing BLEU score for task: HumanEval/115\n",
      "BLEU score: 0.0889696287266969\n",
      "\n",
      "Computing BLEU score for task: HumanEval/116\n",
      "BLEU score: 0.012940749413893492\n",
      "\n",
      "Computing BLEU score for task: HumanEval/117\n",
      "BLEU score: 0.11211689577274028\n",
      "\n",
      "Computing BLEU score for task: HumanEval/118\n",
      "BLEU score: 0.11125187510930297\n",
      "\n",
      "Computing BLEU score for task: HumanEval/119\n",
      "BLEU score: 0.042279297521702994\n",
      "\n",
      "Computing BLEU score for task: HumanEval/120\n",
      "BLEU score: 0.11362193664674995\n",
      "\n",
      "Computing BLEU score for task: HumanEval/121\n",
      "BLEU score: 0.04877324444306589\n",
      "\n",
      "Computing BLEU score for task: HumanEval/122\n",
      "BLEU score: 0.00956240657444202\n",
      "\n",
      "Computing BLEU score for task: HumanEval/123\n",
      "BLEU score: 0.0640040731067511\n",
      "\n",
      "Computing BLEU score for task: HumanEval/124\n",
      "BLEU score: 0.10651789465036461\n",
      "\n",
      "Computing BLEU score for task: HumanEval/125\n",
      "BLEU score: 0.07205940156518365\n",
      "\n",
      "Computing BLEU score for task: HumanEval/126\n",
      "BLEU score: 0.010430060360608557\n",
      "\n",
      "Computing BLEU score for task: HumanEval/127\n",
      "BLEU score: 0.012143307164393926\n",
      "\n",
      "Computing BLEU score for task: HumanEval/128\n",
      "BLEU score: 0.021628820160963114\n",
      "\n",
      "Computing BLEU score for task: HumanEval/129\n",
      "BLEU score: 0.007720284975213914\n",
      "\n",
      "Computing BLEU score for task: HumanEval/130\n",
      "BLEU score: 0.11141294470814965\n",
      "\n",
      "Computing BLEU score for task: HumanEval/131\n",
      "BLEU score: 0.05863302646168854\n",
      "\n",
      "Computing BLEU score for task: HumanEval/132\n",
      "BLEU score: 0.010190738298997176\n",
      "\n",
      "Computing BLEU score for task: HumanEval/133\n",
      "BLEU score: 0.017033186037639283\n",
      "\n",
      "Computing BLEU score for task: HumanEval/134\n",
      "BLEU score: 0.05846112500518281\n",
      "\n",
      "Computing BLEU score for task: HumanEval/135\n",
      "BLEU score: 0.06922521376924558\n",
      "\n",
      "Computing BLEU score for task: HumanEval/136\n",
      "BLEU score: 0.0031291988544132512\n",
      "\n",
      "Computing BLEU score for task: HumanEval/137\n",
      "BLEU score: 0.011055446882286175\n",
      "\n",
      "Computing BLEU score for task: HumanEval/138\n",
      "BLEU score: 0.022934751368971395\n",
      "\n",
      "Computing BLEU score for task: HumanEval/139\n",
      "BLEU score: 0.08863388829112887\n",
      "\n",
      "Computing BLEU score for task: HumanEval/140\n",
      "BLEU score: 0.025897048865718798\n",
      "\n",
      "Computing BLEU score for task: HumanEval/141\n",
      "BLEU score: 0.03523755477067784\n",
      "\n",
      "Computing BLEU score for task: HumanEval/142\n",
      "BLEU score: 0.7131992424981134\n",
      "\n",
      "Computing BLEU score for task: HumanEval/143\n",
      "BLEU score: 0.017345333612331648\n",
      "\n",
      "Computing BLEU score for task: HumanEval/144\n",
      "BLEU score: 0.020053583653512706\n",
      "\n",
      "Computing BLEU score for task: HumanEval/145\n",
      "BLEU score: 0.018018299531677898\n",
      "\n",
      "Computing BLEU score for task: HumanEval/146\n",
      "BLEU score: 0.2350232752505059\n",
      "\n",
      "Computing BLEU score for task: HumanEval/147\n",
      "BLEU score: 0.10989581815552828\n",
      "\n",
      "Computing BLEU score for task: HumanEval/148\n",
      "BLEU score: 0.10573459289334466\n",
      "\n",
      "Computing BLEU score for task: HumanEval/149\n",
      "BLEU score: 0.06977093965985222\n",
      "\n",
      "Computing BLEU score for task: HumanEval/150\n",
      "BLEU score: 0.02566515399876159\n",
      "\n",
      "Computing BLEU score for task: HumanEval/151\n",
      "BLEU score: 0.0963274071288483\n",
      "\n",
      "Computing BLEU score for task: HumanEval/152\n",
      "BLEU score: 0.09578464408619825\n",
      "\n",
      "Computing BLEU score for task: HumanEval/153\n",
      "BLEU score: 0.10212178286063522\n",
      "\n",
      "Computing BLEU score for task: HumanEval/154\n",
      "BLEU score: 0.12675606378132004\n",
      "\n",
      "Computing BLEU score for task: HumanEval/155\n",
      "BLEU score: 0.0367483224173178\n",
      "\n",
      "Computing BLEU score for task: HumanEval/156\n",
      "BLEU score: 0.007219694801021364\n",
      "\n",
      "Computing BLEU score for task: HumanEval/157\n",
      "BLEU score: 0.0039240544574399286\n",
      "\n",
      "Computing BLEU score for task: HumanEval/158\n",
      "BLEU score: 0.16405298564986906\n",
      "\n",
      "Computing BLEU score for task: HumanEval/159\n",
      "BLEU score: 0.06799134307508922\n",
      "\n",
      "Computing BLEU score for task: HumanEval/160\n",
      "BLEU score: 0.054285521517746294\n",
      "\n",
      "Computing BLEU score for task: HumanEval/161\n",
      "BLEU score: 0.03218025292847049\n",
      "\n",
      "Computing BLEU score for task: HumanEval/162\n",
      "BLEU score: 0.10793498849599974\n",
      "\n",
      "Computing BLEU score for task: HumanEval/163\n",
      "BLEU score: 0.03459516500691775\n",
      "Metric BLEU computation complete.\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/0\n",
      "Precision: 0.58\n",
      "Recall: 0.60\n",
      "F1-Score: 0.59\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/1\n",
      "Precision: 0.43\n",
      "Recall: 0.59\n",
      "F1-Score: 0.50\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/2\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/3\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/4\n",
      "Precision: 0.26\n",
      "Recall: 0.75\n",
      "F1-Score: 0.38\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/5\n",
      "Precision: 0.65\n",
      "Recall: 0.62\n",
      "F1-Score: 0.63\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/6\n",
      "Precision: 0.38\n",
      "Recall: 0.36\n",
      "F1-Score: 0.37\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/7\n",
      "Precision: 0.21\n",
      "Recall: 0.33\n",
      "F1-Score: 0.26\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/8\n",
      "Precision: 0.27\n",
      "Recall: 0.60\n",
      "F1-Score: 0.37\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/9\n",
      "Precision: 0.13\n",
      "Recall: 0.36\n",
      "F1-Score: 0.19\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/10\n",
      "Precision: 0.77\n",
      "Recall: 0.87\n",
      "F1-Score: 0.82\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/11\n",
      "Precision: 0.24\n",
      "Recall: 0.53\n",
      "F1-Score: 0.33\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/12\n",
      "Precision: 0.48\n",
      "Recall: 0.52\n",
      "F1-Score: 0.50\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/13\n",
      "Precision: 0.89\n",
      "Recall: 0.33\n",
      "F1-Score: 0.48\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/14\n",
      "Precision: 0.40\n",
      "Recall: 0.60\n",
      "F1-Score: 0.48\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/15\n",
      "Precision: 0.19\n",
      "Recall: 0.57\n",
      "F1-Score: 0.29\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/16\n",
      "Precision: 0.23\n",
      "Recall: 0.60\n",
      "F1-Score: 0.33\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/17\n",
      "Precision: 0.47\n",
      "Recall: 0.53\n",
      "F1-Score: 0.50\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/18\n",
      "Precision: 0.38\n",
      "Recall: 0.76\n",
      "F1-Score: 0.51\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/19\n",
      "Precision: 0.45\n",
      "Recall: 0.67\n",
      "F1-Score: 0.54\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/20\n",
      "Precision: 0.39\n",
      "Recall: 0.69\n",
      "F1-Score: 0.50\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/21\n",
      "Precision: 0.12\n",
      "Recall: 0.37\n",
      "F1-Score: 0.18\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/22\n",
      "Precision: 0.07\n",
      "Recall: 0.22\n",
      "F1-Score: 0.11\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/23\n",
      "Precision: 0.11\n",
      "Recall: 0.33\n",
      "F1-Score: 0.17\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/24\n",
      "Precision: 0.45\n",
      "Recall: 0.87\n",
      "F1-Score: 0.59\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/25\n",
      "Precision: 0.54\n",
      "Recall: 0.44\n",
      "F1-Score: 0.48\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/26\n",
      "Precision: 0.53\n",
      "Recall: 0.50\n",
      "F1-Score: 0.52\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/27\n",
      "Precision: 0.04\n",
      "Recall: 0.12\n",
      "F1-Score: 0.06\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/28\n",
      "Precision: 0.11\n",
      "Recall: 0.33\n",
      "F1-Score: 0.17\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/29\n",
      "Precision: 0.21\n",
      "Recall: 0.33\n",
      "F1-Score: 0.26\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/30\n",
      "Precision: 0.06\n",
      "Recall: 0.12\n",
      "F1-Score: 0.08\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/31\n",
      "Precision: 0.46\n",
      "Recall: 0.56\n",
      "F1-Score: 0.51\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/32\n",
      "Precision: 0.17\n",
      "Recall: 0.18\n",
      "F1-Score: 0.17\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/33\n",
      "Precision: 0.39\n",
      "Recall: 0.53\n",
      "F1-Score: 0.45\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/34\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/35\n",
      "Precision: 0.11\n",
      "Recall: 1.00\n",
      "F1-Score: 0.20\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/36\n",
      "Precision: 0.74\n",
      "Recall: 0.63\n",
      "F1-Score: 0.68\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/37\n",
      "Precision: 0.27\n",
      "Recall: 0.47\n",
      "F1-Score: 0.34\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/38\n",
      "Precision: 0.94\n",
      "Recall: 0.94\n",
      "F1-Score: 0.94\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/39\n",
      "Precision: 0.42\n",
      "Recall: 0.25\n",
      "F1-Score: 0.32\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/40\n",
      "Precision: 0.59\n",
      "Recall: 0.62\n",
      "F1-Score: 0.60\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/41\n",
      "Precision: 0.06\n",
      "Recall: 0.67\n",
      "F1-Score: 0.11\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/42\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/43\n",
      "Precision: 0.47\n",
      "Recall: 0.32\n",
      "F1-Score: 0.38\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/44\n",
      "Precision: 0.65\n",
      "Recall: 0.72\n",
      "F1-Score: 0.68\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/45\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/46\n",
      "Precision: 1.00\n",
      "Recall: 0.98\n",
      "F1-Score: 0.99\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/47\n",
      "Precision: 0.44\n",
      "Recall: 0.41\n",
      "F1-Score: 0.43\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/48\n",
      "Precision: 0.29\n",
      "Recall: 1.00\n",
      "F1-Score: 0.44\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/49\n",
      "Precision: 0.50\n",
      "Recall: 0.58\n",
      "F1-Score: 0.54\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/50\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/51\n",
      "Precision: 0.12\n",
      "Recall: 0.18\n",
      "F1-Score: 0.15\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/52\n",
      "Precision: 0.27\n",
      "Recall: 0.38\n",
      "F1-Score: 0.32\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/53\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/54\n",
      "Precision: 0.43\n",
      "Recall: 0.60\n",
      "F1-Score: 0.50\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/55\n",
      "Precision: 0.83\n",
      "Recall: 0.70\n",
      "F1-Score: 0.76\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/56\n",
      "Precision: 0.42\n",
      "Recall: 0.59\n",
      "F1-Score: 0.49\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/57\n",
      "Precision: 0.81\n",
      "Recall: 0.81\n",
      "F1-Score: 0.81\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/58\n",
      "Precision: 0.55\n",
      "Recall: 0.75\n",
      "F1-Score: 0.63\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/59\n",
      "Precision: 0.21\n",
      "Recall: 0.33\n",
      "F1-Score: 0.25\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/60\n",
      "Precision: 0.15\n",
      "Recall: 0.40\n",
      "F1-Score: 0.22\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/61\n",
      "Precision: 0.46\n",
      "Recall: 0.59\n",
      "F1-Score: 0.52\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/62\n",
      "Precision: 0.42\n",
      "Recall: 0.73\n",
      "F1-Score: 0.53\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/63\n",
      "Precision: 0.89\n",
      "Recall: 0.97\n",
      "F1-Score: 0.93\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/64\n",
      "Precision: 0.24\n",
      "Recall: 0.35\n",
      "F1-Score: 0.29\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/65\n",
      "Precision: 0.84\n",
      "Recall: 0.57\n",
      "F1-Score: 0.68\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/66\n",
      "Precision: 0.27\n",
      "Recall: 0.36\n",
      "F1-Score: 0.31\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/67\n",
      "Precision: 0.47\n",
      "Recall: 0.30\n",
      "F1-Score: 0.37\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/68\n",
      "Precision: 0.32\n",
      "Recall: 0.49\n",
      "F1-Score: 0.39\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/69\n",
      "Precision: 0.16\n",
      "Recall: 0.56\n",
      "F1-Score: 0.25\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/70\n",
      "Precision: 0.15\n",
      "Recall: 0.38\n",
      "F1-Score: 0.21\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/71\n",
      "Precision: 0.19\n",
      "Recall: 0.65\n",
      "F1-Score: 0.29\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/72\n",
      "Precision: 0.05\n",
      "Recall: 1.00\n",
      "F1-Score: 0.10\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/73\n",
      "Precision: 0.64\n",
      "Recall: 0.61\n",
      "F1-Score: 0.62\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/74\n",
      "Precision: 0.11\n",
      "Recall: 0.52\n",
      "F1-Score: 0.18\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/75\n",
      "Precision: 0.37\n",
      "Recall: 0.39\n",
      "F1-Score: 0.38\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/76\n",
      "Precision: 0.56\n",
      "Recall: 0.44\n",
      "F1-Score: 0.49\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/77\n",
      "Precision: 0.11\n",
      "Recall: 0.82\n",
      "F1-Score: 0.19\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/78\n",
      "Precision: 0.10\n",
      "Recall: 0.20\n",
      "F1-Score: 0.13\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/79\n",
      "Precision: 0.15\n",
      "Recall: 0.67\n",
      "F1-Score: 0.25\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/80\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/81\n",
      "Precision: 0.45\n",
      "Recall: 0.63\n",
      "F1-Score: 0.52\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/82\n",
      "Precision: 0.38\n",
      "Recall: 0.36\n",
      "F1-Score: 0.37\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/83\n",
      "Precision: 0.20\n",
      "Recall: 0.80\n",
      "F1-Score: 0.32\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/84\n",
      "Precision: 0.11\n",
      "Recall: 0.31\n",
      "F1-Score: 0.16\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/85\n",
      "Precision: 0.37\n",
      "Recall: 0.85\n",
      "F1-Score: 0.52\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/86\n",
      "Precision: 0.30\n",
      "Recall: 0.35\n",
      "F1-Score: 0.32\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/87\n",
      "Precision: 0.37\n",
      "Recall: 0.54\n",
      "F1-Score: 0.44\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/88\n",
      "Precision: 0.44\n",
      "Recall: 0.85\n",
      "F1-Score: 0.58\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/89\n",
      "Precision: 0.18\n",
      "Recall: 0.39\n",
      "F1-Score: 0.24\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/90\n",
      "Precision: 0.41\n",
      "Recall: 0.50\n",
      "F1-Score: 0.45\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/91\n",
      "Precision: 0.12\n",
      "Recall: 0.43\n",
      "F1-Score: 0.19\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/92\n",
      "Precision: 0.21\n",
      "Recall: 0.77\n",
      "F1-Score: 0.33\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/93\n",
      "Precision: 0.20\n",
      "Recall: 0.20\n",
      "F1-Score: 0.20\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/94\n",
      "Precision: 0.24\n",
      "Recall: 0.46\n",
      "F1-Score: 0.32\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/95\n",
      "Precision: 0.60\n",
      "Recall: 0.62\n",
      "F1-Score: 0.61\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/96\n",
      "Precision: 0.33\n",
      "Recall: 0.43\n",
      "F1-Score: 0.37\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/97\n",
      "Precision: 0.20\n",
      "Recall: 0.33\n",
      "F1-Score: 0.25\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/98\n",
      "Precision: 0.60\n",
      "Recall: 0.79\n",
      "F1-Score: 0.68\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/99\n",
      "Precision: 0.10\n",
      "Recall: 0.52\n",
      "F1-Score: 0.17\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/100\n",
      "Precision: 0.31\n",
      "Recall: 0.57\n",
      "F1-Score: 0.40\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/101\n",
      "Precision: 0.14\n",
      "Recall: 0.08\n",
      "F1-Score: 0.11\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/102\n",
      "Precision: 0.28\n",
      "Recall: 0.44\n",
      "F1-Score: 0.34\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/103\n",
      "Precision: 0.31\n",
      "Recall: 0.69\n",
      "F1-Score: 0.43\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/104\n",
      "Precision: 0.34\n",
      "Recall: 0.48\n",
      "F1-Score: 0.40\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/105\n",
      "Precision: 0.40\n",
      "Recall: 0.23\n",
      "F1-Score: 0.29\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/106\n",
      "Precision: 0.33\n",
      "Recall: 0.35\n",
      "F1-Score: 0.34\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/107\n",
      "Precision: 0.60\n",
      "Recall: 0.71\n",
      "F1-Score: 0.65\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/108\n",
      "Precision: 0.22\n",
      "Recall: 0.26\n",
      "F1-Score: 0.23\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/109\n",
      "Precision: 0.51\n",
      "Recall: 0.79\n",
      "F1-Score: 0.62\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/110\n",
      "Precision: 0.29\n",
      "Recall: 0.35\n",
      "F1-Score: 0.32\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/111\n",
      "Precision: 0.45\n",
      "Recall: 0.48\n",
      "F1-Score: 0.46\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/112\n",
      "Precision: 0.29\n",
      "Recall: 0.33\n",
      "F1-Score: 0.31\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/113\n",
      "Precision: 0.22\n",
      "Recall: 0.25\n",
      "F1-Score: 0.23\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/114\n",
      "Precision: 0.27\n",
      "Recall: 0.34\n",
      "F1-Score: 0.30\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/115\n",
      "Precision: 0.42\n",
      "Recall: 0.57\n",
      "F1-Score: 0.48\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/116\n",
      "Precision: 0.22\n",
      "Recall: 0.16\n",
      "F1-Score: 0.19\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/117\n",
      "Precision: 0.27\n",
      "Recall: 0.38\n",
      "F1-Score: 0.31\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/118\n",
      "Precision: 0.62\n",
      "Recall: 0.57\n",
      "F1-Score: 0.59\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/119\n",
      "Precision: 0.13\n",
      "Recall: 0.41\n",
      "F1-Score: 0.20\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/120\n",
      "Precision: 0.60\n",
      "Recall: 0.50\n",
      "F1-Score: 0.55\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/121\n",
      "Precision: 0.30\n",
      "Recall: 0.68\n",
      "F1-Score: 0.42\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/122\n",
      "Precision: 0.09\n",
      "Recall: 0.11\n",
      "F1-Score: 0.10\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/123\n",
      "Precision: 0.47\n",
      "Recall: 0.53\n",
      "F1-Score: 0.50\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/124\n",
      "Precision: 0.36\n",
      "Recall: 0.32\n",
      "F1-Score: 0.34\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/125\n",
      "Precision: 0.21\n",
      "Recall: 0.51\n",
      "F1-Score: 0.30\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/126\n",
      "Precision: 0.09\n",
      "Recall: 0.56\n",
      "F1-Score: 0.16\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/127\n",
      "Precision: 0.29\n",
      "Recall: 0.40\n",
      "F1-Score: 0.33\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/128\n",
      "Precision: 0.28\n",
      "Recall: 0.39\n",
      "F1-Score: 0.32\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/129\n",
      "Precision: 0.18\n",
      "Recall: 0.23\n",
      "F1-Score: 0.20\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/130\n",
      "Precision: 0.21\n",
      "Recall: 0.58\n",
      "F1-Score: 0.31\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/131\n",
      "Precision: 0.53\n",
      "Recall: 0.55\n",
      "F1-Score: 0.54\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/132\n",
      "Precision: 0.17\n",
      "Recall: 0.35\n",
      "F1-Score: 0.23\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/133\n",
      "Precision: 0.23\n",
      "Recall: 0.25\n",
      "F1-Score: 0.24\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/134\n",
      "Precision: 0.13\n",
      "Recall: 0.75\n",
      "F1-Score: 0.23\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/135\n",
      "Precision: 0.64\n",
      "Recall: 0.70\n",
      "F1-Score: 0.67\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/136\n",
      "Precision: 0.08\n",
      "Recall: 0.31\n",
      "F1-Score: 0.13\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/137\n",
      "Precision: 0.21\n",
      "Recall: 0.57\n",
      "F1-Score: 0.30\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/138\n",
      "Precision: 0.10\n",
      "Recall: 0.71\n",
      "F1-Score: 0.18\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/139\n",
      "Precision: 0.26\n",
      "Recall: 0.59\n",
      "F1-Score: 0.36\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/140\n",
      "Precision: 0.50\n",
      "Recall: 0.29\n",
      "F1-Score: 0.37\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/141\n",
      "Precision: 0.54\n",
      "Recall: 0.56\n",
      "F1-Score: 0.55\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/142\n",
      "Precision: 0.69\n",
      "Recall: 0.81\n",
      "F1-Score: 0.75\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/143\n",
      "Precision: 0.37\n",
      "Recall: 0.51\n",
      "F1-Score: 0.43\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/144\n",
      "Precision: 0.12\n",
      "Recall: 0.33\n",
      "F1-Score: 0.18\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/145\n",
      "Precision: 0.23\n",
      "Recall: 0.15\n",
      "F1-Score: 0.18\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/146\n",
      "Precision: 0.50\n",
      "Recall: 0.52\n",
      "F1-Score: 0.51\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/147\n",
      "Precision: 0.17\n",
      "Recall: 0.28\n",
      "F1-Score: 0.21\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/148\n",
      "Precision: 0.20\n",
      "Recall: 0.71\n",
      "F1-Score: 0.31\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/149\n",
      "Precision: 0.42\n",
      "Recall: 0.22\n",
      "F1-Score: 0.29\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/150\n",
      "Precision: 0.52\n",
      "Recall: 0.39\n",
      "F1-Score: 0.44\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/151\n",
      "Precision: 0.15\n",
      "Recall: 0.65\n",
      "F1-Score: 0.25\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/152\n",
      "Precision: 0.38\n",
      "Recall: 0.50\n",
      "F1-Score: 0.43\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/153\n",
      "Precision: 0.41\n",
      "Recall: 0.49\n",
      "F1-Score: 0.44\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/154\n",
      "Precision: 0.55\n",
      "Recall: 0.44\n",
      "F1-Score: 0.49\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/155\n",
      "Precision: 0.33\n",
      "Recall: 0.58\n",
      "F1-Score: 0.42\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/156\n",
      "Precision: 0.17\n",
      "Recall: 0.18\n",
      "F1-Score: 0.18\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/157\n",
      "Precision: 0.14\n",
      "Recall: 0.62\n",
      "F1-Score: 0.23\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/158\n",
      "Precision: 0.28\n",
      "Recall: 0.29\n",
      "F1-Score: 0.28\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/159\n",
      "Precision: 0.56\n",
      "Recall: 0.38\n",
      "F1-Score: 0.45\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/160\n",
      "Precision: 0.29\n",
      "Recall: 0.55\n",
      "F1-Score: 0.38\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/161\n",
      "Precision: 0.39\n",
      "Recall: 0.57\n",
      "F1-Score: 0.46\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/162\n",
      "Precision: 0.94\n",
      "Recall: 0.89\n",
      "F1-Score: 0.91\n",
      "\n",
      "Computing ROUGE-L score for task: HumanEval/163\n",
      "Precision: 0.34\n",
      "Recall: 0.50\n",
      "F1-Score: 0.41\n",
      "Metric ROUGE computation complete.\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/0\n",
      "Precision: 0.91\n",
      "Recall: 0.89\n",
      "F1-score: 0.90\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/1\n",
      "Precision: 0.83\n",
      "Recall: 0.87\n",
      "F1-score: 0.85\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/2\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "F3-score: 1.00\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/3\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1-score: 0.98\n",
      "F3-score: 0.98\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/4\n",
      "Precision: 0.75\n",
      "Recall: 0.90\n",
      "F1-score: 0.82\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/5\n",
      "Precision: 0.93\n",
      "Recall: 0.95\n",
      "F1-score: 0.94\n",
      "F3-score: 0.95\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/6\n",
      "Precision: 0.85\n",
      "Recall: 0.83\n",
      "F1-score: 0.84\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/7\n",
      "Precision: 0.79\n",
      "Recall: 0.81\n",
      "F1-score: 0.80\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/8\n",
      "Precision: 0.76\n",
      "Recall: 0.85\n",
      "F1-score: 0.80\n",
      "F3-score: 0.84\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/9\n",
      "Precision: 0.69\n",
      "Recall: 0.73\n",
      "F1-score: 0.71\n",
      "F3-score: 0.72\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/10\n",
      "Precision: 0.93\n",
      "Recall: 0.94\n",
      "F1-score: 0.94\n",
      "F3-score: 0.94\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/11\n",
      "Precision: 0.71\n",
      "Recall: 0.83\n",
      "F1-score: 0.76\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/12\n",
      "Precision: 0.87\n",
      "Recall: 0.89\n",
      "F1-score: 0.88\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/13\n",
      "Precision: 0.87\n",
      "Recall: 0.76\n",
      "F1-score: 0.81\n",
      "F3-score: 0.77\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/14\n",
      "Precision: 0.82\n",
      "Recall: 0.90\n",
      "F1-score: 0.86\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/15\n",
      "Precision: 0.71\n",
      "Recall: 0.78\n",
      "F1-score: 0.74\n",
      "F3-score: 0.77\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/16\n",
      "Precision: 0.78\n",
      "Recall: 0.88\n",
      "F1-score: 0.83\n",
      "F3-score: 0.87\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/17\n",
      "Precision: 0.82\n",
      "Recall: 0.83\n",
      "F1-score: 0.83\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/18\n",
      "Precision: 0.81\n",
      "Recall: 0.84\n",
      "F1-score: 0.83\n",
      "F3-score: 0.84\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/19\n",
      "Precision: 0.79\n",
      "Recall: 0.87\n",
      "F1-score: 0.83\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/20\n",
      "Precision: 0.79\n",
      "Recall: 0.87\n",
      "F1-score: 0.83\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/21\n",
      "Precision: 0.72\n",
      "Recall: 0.77\n",
      "F1-score: 0.75\n",
      "F3-score: 0.77\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/22\n",
      "Precision: 0.68\n",
      "Recall: 0.76\n",
      "F1-score: 0.71\n",
      "F3-score: 0.75\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/23\n",
      "Precision: 0.70\n",
      "Recall: 0.79\n",
      "F1-score: 0.74\n",
      "F3-score: 0.78\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/24\n",
      "Precision: 0.79\n",
      "Recall: 0.92\n",
      "F1-score: 0.85\n",
      "F3-score: 0.90\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/25\n",
      "Precision: 0.87\n",
      "Recall: 0.84\n",
      "F1-score: 0.86\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/26\n",
      "Precision: 0.89\n",
      "Recall: 0.86\n",
      "F1-score: 0.87\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/27\n",
      "Precision: 0.66\n",
      "Recall: 0.69\n",
      "F1-score: 0.67\n",
      "F3-score: 0.69\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/28\n",
      "Precision: 0.76\n",
      "Recall: 0.80\n",
      "F1-score: 0.78\n",
      "F3-score: 0.80\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/29\n",
      "Precision: 0.79\n",
      "Recall: 0.82\n",
      "F1-score: 0.81\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/30\n",
      "Precision: 0.72\n",
      "Recall: 0.77\n",
      "F1-score: 0.74\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/31\n",
      "Precision: 0.88\n",
      "Recall: 0.82\n",
      "F1-score: 0.85\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/32\n",
      "Precision: 0.72\n",
      "Recall: 0.72\n",
      "F1-score: 0.72\n",
      "F3-score: 0.72\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/33\n",
      "Precision: 0.76\n",
      "Recall: 0.84\n",
      "F1-score: 0.80\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/34\n",
      "Precision: 0.97\n",
      "Recall: 0.99\n",
      "F1-score: 0.98\n",
      "F3-score: 0.99\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/35\n",
      "Precision: 0.66\n",
      "Recall: 0.77\n",
      "F1-score: 0.71\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/36\n",
      "Precision: 0.94\n",
      "Recall: 0.89\n",
      "F1-score: 0.91\n",
      "F3-score: 0.90\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/37\n",
      "Precision: 0.74\n",
      "Recall: 0.83\n",
      "F1-score: 0.78\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/38\n",
      "Precision: 0.97\n",
      "Recall: 0.99\n",
      "F1-score: 0.98\n",
      "F3-score: 0.98\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/39\n",
      "Precision: 0.78\n",
      "Recall: 0.75\n",
      "F1-score: 0.76\n",
      "F3-score: 0.75\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/40\n",
      "Precision: 0.86\n",
      "Recall: 0.91\n",
      "F1-score: 0.88\n",
      "F3-score: 0.90\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/41\n",
      "Precision: 0.62\n",
      "Recall: 0.72\n",
      "F1-score: 0.66\n",
      "F3-score: 0.71\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/42\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "F3-score: 1.00\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/43\n",
      "Precision: 0.79\n",
      "Recall: 0.78\n",
      "F1-score: 0.79\n",
      "F3-score: 0.78\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/44\n",
      "Precision: 0.91\n",
      "Recall: 0.95\n",
      "F1-score: 0.93\n",
      "F3-score: 0.95\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/45\n",
      "Precision: 0.93\n",
      "Recall: 0.93\n",
      "F1-score: 0.93\n",
      "F3-score: 0.93\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/46\n",
      "Precision: 1.00\n",
      "Recall: 0.99\n",
      "F1-score: 1.00\n",
      "F3-score: 0.99\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/47\n",
      "Precision: 0.85\n",
      "Recall: 0.86\n",
      "F1-score: 0.86\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/48\n",
      "Precision: 0.77\n",
      "Recall: 0.90\n",
      "F1-score: 0.83\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/49\n",
      "Precision: 0.87\n",
      "Recall: 0.91\n",
      "F1-score: 0.89\n",
      "F3-score: 0.90\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting precision and recall to be 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n",
      "F3-score: 0.00\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/51\n",
      "Precision: 0.80\n",
      "Recall: 0.85\n",
      "F1-score: 0.83\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/52\n",
      "Precision: 0.78\n",
      "Recall: 0.81\n",
      "F1-score: 0.79\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/53\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-score: 1.00\n",
      "F3-score: 1.00\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/54\n",
      "Precision: 0.91\n",
      "Recall: 0.95\n",
      "F1-score: 0.93\n",
      "F3-score: 0.94\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/55\n",
      "Precision: 0.95\n",
      "Recall: 0.94\n",
      "F1-score: 0.94\n",
      "F3-score: 0.94\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/56\n",
      "Precision: 0.84\n",
      "Recall: 0.88\n",
      "F1-score: 0.86\n",
      "F3-score: 0.88\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/57\n",
      "Precision: 0.94\n",
      "Recall: 0.94\n",
      "F1-score: 0.94\n",
      "F3-score: 0.94\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/58\n",
      "Precision: 0.86\n",
      "Recall: 0.91\n",
      "F1-score: 0.88\n",
      "F3-score: 0.90\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/59\n",
      "Precision: 0.74\n",
      "Recall: 0.76\n",
      "F1-score: 0.75\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/60\n",
      "Precision: 0.74\n",
      "Recall: 0.79\n",
      "F1-score: 0.76\n",
      "F3-score: 0.78\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/61\n",
      "Precision: 0.86\n",
      "Recall: 0.88\n",
      "F1-score: 0.87\n",
      "F3-score: 0.87\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/62\n",
      "Precision: 0.83\n",
      "Recall: 0.92\n",
      "F1-score: 0.87\n",
      "F3-score: 0.91\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/63\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n",
      "F1-score: 0.96\n",
      "F3-score: 0.96\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/64\n",
      "Precision: 0.80\n",
      "Recall: 0.82\n",
      "F1-score: 0.81\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/65\n",
      "Precision: 0.92\n",
      "Recall: 0.90\n",
      "F1-score: 0.91\n",
      "F3-score: 0.91\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/66\n",
      "Precision: 0.81\n",
      "Recall: 0.84\n",
      "F1-score: 0.82\n",
      "F3-score: 0.84\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/67\n",
      "Precision: 0.87\n",
      "Recall: 0.78\n",
      "F1-score: 0.82\n",
      "F3-score: 0.79\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/68\n",
      "Precision: 0.80\n",
      "Recall: 0.83\n",
      "F1-score: 0.81\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/69\n",
      "Precision: 0.68\n",
      "Recall: 0.76\n",
      "F1-score: 0.71\n",
      "F3-score: 0.75\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/70\n",
      "Precision: 0.69\n",
      "Recall: 0.75\n",
      "F1-score: 0.72\n",
      "F3-score: 0.75\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/71\n",
      "Precision: 0.70\n",
      "Recall: 0.81\n",
      "F1-score: 0.75\n",
      "F3-score: 0.80\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/72\n",
      "Precision: 0.51\n",
      "Recall: 0.75\n",
      "F1-score: 0.61\n",
      "F3-score: 0.72\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/73\n",
      "Precision: 0.88\n",
      "Recall: 0.82\n",
      "F1-score: 0.85\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/74\n",
      "Precision: 0.61\n",
      "Recall: 0.74\n",
      "F1-score: 0.67\n",
      "F3-score: 0.72\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/75\n",
      "Precision: 0.80\n",
      "Recall: 0.83\n",
      "F1-score: 0.82\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/76\n",
      "Precision: 0.89\n",
      "Recall: 0.89\n",
      "F1-score: 0.89\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/77\n",
      "Precision: 0.61\n",
      "Recall: 0.74\n",
      "F1-score: 0.67\n",
      "F3-score: 0.72\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/78\n",
      "Precision: 0.69\n",
      "Recall: 0.72\n",
      "F1-score: 0.71\n",
      "F3-score: 0.72\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/79\n",
      "Precision: 0.72\n",
      "Recall: 0.82\n",
      "F1-score: 0.77\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/80\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "F1-score: 0.98\n",
      "F3-score: 0.98\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/81\n",
      "Precision: 0.86\n",
      "Recall: 0.89\n",
      "F1-score: 0.87\n",
      "F3-score: 0.88\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/82\n",
      "Precision: 0.84\n",
      "Recall: 0.82\n",
      "F1-score: 0.83\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/83\n",
      "Precision: 0.76\n",
      "Recall: 0.88\n",
      "F1-score: 0.81\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/84\n",
      "Precision: 0.68\n",
      "Recall: 0.77\n",
      "F1-score: 0.72\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/85\n",
      "Precision: 0.79\n",
      "Recall: 0.94\n",
      "F1-score: 0.86\n",
      "F3-score: 0.93\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/86\n",
      "Precision: 0.83\n",
      "Recall: 0.82\n",
      "F1-score: 0.83\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/87\n",
      "Precision: 0.82\n",
      "Recall: 0.82\n",
      "F1-score: 0.82\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/88\n",
      "Precision: 0.83\n",
      "Recall: 0.90\n",
      "F1-score: 0.86\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/89\n",
      "Precision: 0.77\n",
      "Recall: 0.74\n",
      "F1-score: 0.76\n",
      "F3-score: 0.74\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/90\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1-score: 0.84\n",
      "F3-score: 0.84\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/91\n",
      "Precision: 0.67\n",
      "Recall: 0.79\n",
      "F1-score: 0.73\n",
      "F3-score: 0.78\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/92\n",
      "Precision: 0.66\n",
      "Recall: 0.77\n",
      "F1-score: 0.71\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/93\n",
      "Precision: 0.79\n",
      "Recall: 0.79\n",
      "F1-score: 0.79\n",
      "F3-score: 0.79\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/94\n",
      "Precision: 0.75\n",
      "Recall: 0.82\n",
      "F1-score: 0.78\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/95\n",
      "Precision: 0.88\n",
      "Recall: 0.89\n",
      "F1-score: 0.88\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/96\n",
      "Precision: 0.81\n",
      "Recall: 0.86\n",
      "F1-score: 0.83\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/97\n",
      "Precision: 0.82\n",
      "Recall: 0.78\n",
      "F1-score: 0.80\n",
      "F3-score: 0.78\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/98\n",
      "Precision: 0.90\n",
      "Recall: 0.94\n",
      "F1-score: 0.92\n",
      "F3-score: 0.94\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/99\n",
      "Precision: 0.66\n",
      "Recall: 0.78\n",
      "F1-score: 0.71\n",
      "F3-score: 0.77\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/100\n",
      "Precision: 0.79\n",
      "Recall: 0.88\n",
      "F1-score: 0.83\n",
      "F3-score: 0.87\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/101\n",
      "Precision: 0.72\n",
      "Recall: 0.74\n",
      "F1-score: 0.73\n",
      "F3-score: 0.73\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/102\n",
      "Precision: 0.73\n",
      "Recall: 0.84\n",
      "F1-score: 0.78\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/103\n",
      "Precision: 0.81\n",
      "Recall: 0.88\n",
      "F1-score: 0.84\n",
      "F3-score: 0.87\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/104\n",
      "Precision: 0.80\n",
      "Recall: 0.82\n",
      "F1-score: 0.81\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/105\n",
      "Precision: 0.76\n",
      "Recall: 0.70\n",
      "F1-score: 0.73\n",
      "F3-score: 0.71\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/106\n",
      "Precision: 0.82\n",
      "Recall: 0.82\n",
      "F1-score: 0.82\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/107\n",
      "Precision: 0.90\n",
      "Recall: 0.94\n",
      "F1-score: 0.92\n",
      "F3-score: 0.93\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/108\n",
      "Precision: 0.73\n",
      "Recall: 0.74\n",
      "F1-score: 0.74\n",
      "F3-score: 0.74\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/109\n",
      "Precision: 0.82\n",
      "Recall: 0.89\n",
      "F1-score: 0.86\n",
      "F3-score: 0.89\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/110\n",
      "Precision: 0.83\n",
      "Recall: 0.81\n",
      "F1-score: 0.82\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/111\n",
      "Precision: 0.87\n",
      "Recall: 0.85\n",
      "F1-score: 0.86\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/112\n",
      "Precision: 0.85\n",
      "Recall: 0.86\n",
      "F1-score: 0.85\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/113\n",
      "Precision: 0.77\n",
      "Recall: 0.81\n",
      "F1-score: 0.79\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/114\n",
      "Precision: 0.75\n",
      "Recall: 0.83\n",
      "F1-score: 0.79\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/115\n",
      "Precision: 0.89\n",
      "Recall: 0.93\n",
      "F1-score: 0.91\n",
      "F3-score: 0.92\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/116\n",
      "Precision: 0.79\n",
      "Recall: 0.75\n",
      "F1-score: 0.77\n",
      "F3-score: 0.75\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/117\n",
      "Precision: 0.81\n",
      "Recall: 0.83\n",
      "F1-score: 0.82\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/118\n",
      "Precision: 0.90\n",
      "Recall: 0.86\n",
      "F1-score: 0.88\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/119\n",
      "Precision: 0.68\n",
      "Recall: 0.75\n",
      "F1-score: 0.71\n",
      "F3-score: 0.74\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/120\n",
      "Precision: 0.87\n",
      "Recall: 0.84\n",
      "F1-score: 0.86\n",
      "F3-score: 0.84\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/121\n",
      "Precision: 0.75\n",
      "Recall: 0.87\n",
      "F1-score: 0.81\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/122\n",
      "Precision: 0.72\n",
      "Recall: 0.72\n",
      "F1-score: 0.72\n",
      "F3-score: 0.72\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/123\n",
      "Precision: 0.82\n",
      "Recall: 0.85\n",
      "F1-score: 0.83\n",
      "F3-score: 0.84\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/124\n",
      "Precision: 0.82\n",
      "Recall: 0.81\n",
      "F1-score: 0.82\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/125\n",
      "Precision: 0.71\n",
      "Recall: 0.77\n",
      "F1-score: 0.74\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/126\n",
      "Precision: 0.60\n",
      "Recall: 0.72\n",
      "F1-score: 0.65\n",
      "F3-score: 0.70\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/127\n",
      "Precision: 0.79\n",
      "Recall: 0.81\n",
      "F1-score: 0.80\n",
      "F3-score: 0.80\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/128\n",
      "Precision: 0.78\n",
      "Recall: 0.83\n",
      "F1-score: 0.80\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/129\n",
      "Precision: 0.72\n",
      "Recall: 0.76\n",
      "F1-score: 0.74\n",
      "F3-score: 0.75\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/130\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n",
      "F1-score: 0.78\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/131\n",
      "Precision: 0.91\n",
      "Recall: 0.90\n",
      "F1-score: 0.91\n",
      "F3-score: 0.90\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/132\n",
      "Precision: 0.70\n",
      "Recall: 0.78\n",
      "F1-score: 0.74\n",
      "F3-score: 0.77\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/133\n",
      "Precision: 0.83\n",
      "Recall: 0.85\n",
      "F1-score: 0.84\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/134\n",
      "Precision: 0.64\n",
      "Recall: 0.74\n",
      "F1-score: 0.69\n",
      "F3-score: 0.73\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/135\n",
      "Precision: 0.87\n",
      "Recall: 0.90\n",
      "F1-score: 0.89\n",
      "F3-score: 0.90\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/136\n",
      "Precision: 0.62\n",
      "Recall: 0.71\n",
      "F1-score: 0.66\n",
      "F3-score: 0.70\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/137\n",
      "Precision: 0.68\n",
      "Recall: 0.78\n",
      "F1-score: 0.73\n",
      "F3-score: 0.77\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/138\n",
      "Precision: 0.66\n",
      "Recall: 0.82\n",
      "F1-score: 0.73\n",
      "F3-score: 0.80\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/139\n",
      "Precision: 0.75\n",
      "Recall: 0.84\n",
      "F1-score: 0.79\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/140\n",
      "Precision: 0.86\n",
      "Recall: 0.77\n",
      "F1-score: 0.81\n",
      "F3-score: 0.77\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/141\n",
      "Precision: 0.87\n",
      "Recall: 0.87\n",
      "F1-score: 0.87\n",
      "F3-score: 0.87\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/142\n",
      "Precision: 0.94\n",
      "Recall: 0.97\n",
      "F1-score: 0.95\n",
      "F3-score: 0.96\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/143\n",
      "Precision: 0.83\n",
      "Recall: 0.85\n",
      "F1-score: 0.84\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/144\n",
      "Precision: 0.74\n",
      "Recall: 0.82\n",
      "F1-score: 0.78\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/145\n",
      "Precision: 0.77\n",
      "Recall: 0.76\n",
      "F1-score: 0.76\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/146\n",
      "Precision: 0.88\n",
      "Recall: 0.86\n",
      "F1-score: 0.87\n",
      "F3-score: 0.86\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/147\n",
      "Precision: 0.78\n",
      "Recall: 0.81\n",
      "F1-score: 0.79\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/148\n",
      "Precision: 0.72\n",
      "Recall: 0.82\n",
      "F1-score: 0.77\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/149\n",
      "Precision: 0.83\n",
      "Recall: 0.75\n",
      "F1-score: 0.79\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/150\n",
      "Precision: 0.89\n",
      "Recall: 0.82\n",
      "F1-score: 0.85\n",
      "F3-score: 0.83\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/151\n",
      "Precision: 0.66\n",
      "Recall: 0.77\n",
      "F1-score: 0.71\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/152\n",
      "Precision: 0.89\n",
      "Recall: 0.94\n",
      "F1-score: 0.91\n",
      "F3-score: 0.93\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/153\n",
      "Precision: 0.80\n",
      "Recall: 0.81\n",
      "F1-score: 0.81\n",
      "F3-score: 0.81\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/154\n",
      "Precision: 0.85\n",
      "Recall: 0.88\n",
      "F1-score: 0.87\n",
      "F3-score: 0.88\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/155\n",
      "Precision: 0.78\n",
      "Recall: 0.83\n",
      "F1-score: 0.81\n",
      "F3-score: 0.82\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/156\n",
      "Precision: 0.72\n",
      "Recall: 0.77\n",
      "F1-score: 0.74\n",
      "F3-score: 0.76\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/157\n",
      "Precision: 0.62\n",
      "Recall: 0.76\n",
      "F1-score: 0.68\n",
      "F3-score: 0.74\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/158\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-score: 0.80\n",
      "F3-score: 0.80\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/159\n",
      "Precision: 0.83\n",
      "Recall: 0.85\n",
      "F1-score: 0.84\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/160\n",
      "Precision: 0.70\n",
      "Recall: 0.81\n",
      "F1-score: 0.75\n",
      "F3-score: 0.80\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/161\n",
      "Precision: 0.85\n",
      "Recall: 0.85\n",
      "F1-score: 0.85\n",
      "F3-score: 0.85\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/162\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n",
      "F1-score: 0.97\n",
      "F3-score: 0.97\n",
      "\n",
      "Computing CodeBERTScore for task: HumanEval/163\n",
      "Precision: 0.79\n",
      "Recall: 0.85\n",
      "F1-score: 0.82\n",
      "F3-score: 0.84\n",
      "Metric BERT computation complete.\n",
      "\n",
      "Computing chrF score for task: HumanEval/0\n",
      "chrF F1-score: 0.22\n",
      "chrF F1-score (macro-averaged): 0.22\n",
      "chrF Precision: 0.22\n",
      "chrF Recall: 0.22\n",
      "\n",
      "Computing chrF score for task: HumanEval/1\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "\n",
      "Computing chrF score for task: HumanEval/2\n",
      "chrF F1-score: 1.00\n",
      "chrF F1-score (macro-averaged): 1.00\n",
      "chrF Precision: 1.00\n",
      "chrF Recall: 1.00\n",
      "\n",
      "Computing chrF score for task: HumanEval/3\n",
      "chrF F1-score: 0.73\n",
      "chrF F1-score (macro-averaged): 0.73\n",
      "chrF Precision: 0.73\n",
      "chrF Recall: 0.73\n",
      "\n",
      "Computing chrF score for task: HumanEval/4\n",
      "chrF F1-score: 0.15\n",
      "chrF F1-score (macro-averaged): 0.15\n",
      "chrF Precision: 0.15\n",
      "chrF Recall: 0.15\n",
      "\n",
      "Computing chrF score for task: HumanEval/5\n",
      "chrF F1-score: 0.62\n",
      "chrF F1-score (macro-averaged): 0.62\n",
      "chrF Precision: 0.62\n",
      "chrF Recall: 0.62\n",
      "\n",
      "Computing chrF score for task: HumanEval/6\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/7\n",
      "chrF F1-score: 0.03\n",
      "chrF F1-score (macro-averaged): 0.03\n",
      "chrF Precision: 0.03\n",
      "chrF Recall: 0.03\n",
      "\n",
      "Computing chrF score for task: HumanEval/8\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/9\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/10\n",
      "chrF F1-score: 0.24\n",
      "chrF F1-score (macro-averaged): 0.24\n",
      "chrF Precision: 0.24\n",
      "chrF Recall: 0.24\n",
      "\n",
      "Computing chrF score for task: HumanEval/11\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "\n",
      "Computing chrF score for task: HumanEval/12\n",
      "chrF F1-score: 0.49\n",
      "chrF F1-score (macro-averaged): 0.49\n",
      "chrF Precision: 0.49\n",
      "chrF Recall: 0.49\n",
      "\n",
      "Computing chrF score for task: HumanEval/13\n",
      "chrF F1-score: 0.15\n",
      "chrF F1-score (macro-averaged): 0.15\n",
      "chrF Precision: 0.15\n",
      "chrF Recall: 0.15\n",
      "\n",
      "Computing chrF score for task: HumanEval/14\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/15\n",
      "chrF F1-score: 0.01\n",
      "chrF F1-score (macro-averaged): 0.01\n",
      "chrF Precision: 0.01\n",
      "chrF Recall: 0.01\n",
      "\n",
      "Computing chrF score for task: HumanEval/16\n",
      "chrF F1-score: 0.12\n",
      "chrF F1-score (macro-averaged): 0.12\n",
      "chrF Precision: 0.12\n",
      "chrF Recall: 0.12\n",
      "\n",
      "Computing chrF score for task: HumanEval/17\n",
      "chrF F1-score: 0.17\n",
      "chrF F1-score (macro-averaged): 0.17\n",
      "chrF Precision: 0.17\n",
      "chrF Recall: 0.17\n",
      "\n",
      "Computing chrF score for task: HumanEval/18\n",
      "chrF F1-score: 0.12\n",
      "chrF F1-score (macro-averaged): 0.12\n",
      "chrF Precision: 0.12\n",
      "chrF Recall: 0.12\n",
      "\n",
      "Computing chrF score for task: HumanEval/19\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/20\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/21\n",
      "chrF F1-score: 0.11\n",
      "chrF F1-score (macro-averaged): 0.11\n",
      "chrF Precision: 0.11\n",
      "chrF Recall: 0.11\n",
      "\n",
      "Computing chrF score for task: HumanEval/22\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/23\n",
      "chrF F1-score: 0.03\n",
      "chrF F1-score (macro-averaged): 0.03\n",
      "chrF Precision: 0.03\n",
      "chrF Recall: 0.03\n",
      "\n",
      "Computing chrF score for task: HumanEval/24\n",
      "chrF F1-score: 0.57\n",
      "chrF F1-score (macro-averaged): 0.57\n",
      "chrF Precision: 0.57\n",
      "chrF Recall: 0.57\n",
      "\n",
      "Computing chrF score for task: HumanEval/25\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/26\n",
      "chrF F1-score: 0.13\n",
      "chrF F1-score (macro-averaged): 0.13\n",
      "chrF Precision: 0.13\n",
      "chrF Recall: 0.13\n",
      "\n",
      "Computing chrF score for task: HumanEval/27\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/28\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/29\n",
      "chrF F1-score: 0.02\n",
      "chrF F1-score (macro-averaged): 0.02\n",
      "chrF Precision: 0.02\n",
      "chrF Recall: 0.02\n",
      "\n",
      "Computing chrF score for task: HumanEval/30\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/31\n",
      "chrF F1-score: 0.32\n",
      "chrF F1-score (macro-averaged): 0.32\n",
      "chrF Precision: 0.32\n",
      "chrF Recall: 0.32\n",
      "\n",
      "Computing chrF score for task: HumanEval/32\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/33\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/34\n",
      "chrF F1-score: 0.71\n",
      "chrF F1-score (macro-averaged): 0.71\n",
      "chrF Precision: 0.71\n",
      "chrF Recall: 0.71\n",
      "\n",
      "Computing chrF score for task: HumanEval/35\n",
      "chrF F1-score: 0.03\n",
      "chrF F1-score (macro-averaged): 0.03\n",
      "chrF Precision: 0.03\n",
      "chrF Recall: 0.03\n",
      "\n",
      "Computing chrF score for task: HumanEval/36\n",
      "chrF F1-score: 0.54\n",
      "chrF F1-score (macro-averaged): 0.54\n",
      "chrF Precision: 0.54\n",
      "chrF Recall: 0.54\n",
      "\n",
      "Computing chrF score for task: HumanEval/37\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/38\n",
      "chrF F1-score: 0.94\n",
      "chrF F1-score (macro-averaged): 0.94\n",
      "chrF Precision: 0.94\n",
      "chrF Recall: 0.94\n",
      "\n",
      "Computing chrF score for task: HumanEval/39\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/40\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/41\n",
      "chrF F1-score: 0.03\n",
      "chrF F1-score (macro-averaged): 0.03\n",
      "chrF Precision: 0.03\n",
      "chrF Recall: 0.03\n",
      "\n",
      "Computing chrF score for task: HumanEval/42\n",
      "chrF F1-score: 1.00\n",
      "chrF F1-score (macro-averaged): 1.00\n",
      "chrF Precision: 1.00\n",
      "chrF Recall: 1.00\n",
      "\n",
      "Computing chrF score for task: HumanEval/43\n",
      "chrF F1-score: 0.17\n",
      "chrF F1-score (macro-averaged): 0.17\n",
      "chrF Precision: 0.17\n",
      "chrF Recall: 0.17\n",
      "\n",
      "Computing chrF score for task: HumanEval/44\n",
      "chrF F1-score: 0.20\n",
      "chrF F1-score (macro-averaged): 0.20\n",
      "chrF Precision: 0.20\n",
      "chrF Recall: 0.20\n",
      "\n",
      "Computing chrF score for task: HumanEval/45\n",
      "chrF F1-score: 0.57\n",
      "chrF F1-score (macro-averaged): 0.57\n",
      "chrF Precision: 0.57\n",
      "chrF Recall: 0.57\n",
      "\n",
      "Computing chrF score for task: HumanEval/46\n",
      "chrF F1-score: 0.03\n",
      "chrF F1-score (macro-averaged): 0.03\n",
      "chrF Precision: 0.03\n",
      "chrF Recall: 0.03\n",
      "\n",
      "Computing chrF score for task: HumanEval/47\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/48\n",
      "chrF F1-score: 0.16\n",
      "chrF F1-score (macro-averaged): 0.16\n",
      "chrF Precision: 0.16\n",
      "chrF Recall: 0.16\n",
      "\n",
      "Computing chrF score for task: HumanEval/49\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "\n",
      "Computing chrF score for task: HumanEval/50\n",
      "chrF F1-score: 0.00\n",
      "chrF F1-score (macro-averaged): 0.00\n",
      "chrF Precision: 0.00\n",
      "chrF Recall: 0.00\n",
      "\n",
      "Computing chrF score for task: HumanEval/51\n",
      "chrF F1-score: 0.16\n",
      "chrF F1-score (macro-averaged): 0.16\n",
      "chrF Precision: 0.16\n",
      "chrF Recall: 0.16\n",
      "\n",
      "Computing chrF score for task: HumanEval/52\n",
      "chrF F1-score: 0.17\n",
      "chrF F1-score (macro-averaged): 0.17\n",
      "chrF Precision: 0.17\n",
      "chrF Recall: 0.17\n",
      "\n",
      "Computing chrF score for task: HumanEval/53\n",
      "chrF F1-score: 1.00\n",
      "chrF F1-score (macro-averaged): 1.00\n",
      "chrF Precision: 1.00\n",
      "chrF Recall: 1.00\n",
      "\n",
      "Computing chrF score for task: HumanEval/54\n",
      "chrF F1-score: 0.48\n",
      "chrF F1-score (macro-averaged): 0.48\n",
      "chrF Precision: 0.48\n",
      "chrF Recall: 0.48\n",
      "\n",
      "Computing chrF score for task: HumanEval/55\n",
      "chrF F1-score: 0.15\n",
      "chrF F1-score (macro-averaged): 0.15\n",
      "chrF Precision: 0.15\n",
      "chrF Recall: 0.15\n",
      "\n",
      "Computing chrF score for task: HumanEval/56\n",
      "chrF F1-score: 0.29\n",
      "chrF F1-score (macro-averaged): 0.29\n",
      "chrF Precision: 0.29\n",
      "chrF Recall: 0.29\n",
      "\n",
      "Computing chrF score for task: HumanEval/57\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "\n",
      "Computing chrF score for task: HumanEval/58\n",
      "chrF F1-score: 0.44\n",
      "chrF F1-score (macro-averaged): 0.44\n",
      "chrF Precision: 0.44\n",
      "chrF Recall: 0.44\n",
      "\n",
      "Computing chrF score for task: HumanEval/59\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/60\n",
      "chrF F1-score: 0.01\n",
      "chrF F1-score (macro-averaged): 0.01\n",
      "chrF Precision: 0.01\n",
      "chrF Recall: 0.01\n",
      "\n",
      "Computing chrF score for task: HumanEval/61\n",
      "chrF F1-score: 0.29\n",
      "chrF F1-score (macro-averaged): 0.29\n",
      "chrF Precision: 0.29\n",
      "chrF Recall: 0.29\n",
      "\n",
      "Computing chrF score for task: HumanEval/62\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/63\n",
      "chrF F1-score: 0.23\n",
      "chrF F1-score (macro-averaged): 0.23\n",
      "chrF Precision: 0.23\n",
      "chrF Recall: 0.23\n",
      "\n",
      "Computing chrF score for task: HumanEval/64\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/65\n",
      "chrF F1-score: 0.47\n",
      "chrF F1-score (macro-averaged): 0.47\n",
      "chrF Precision: 0.47\n",
      "chrF Recall: 0.47\n",
      "\n",
      "Computing chrF score for task: HumanEval/66\n",
      "chrF F1-score: 0.01\n",
      "chrF F1-score (macro-averaged): 0.01\n",
      "chrF Precision: 0.01\n",
      "chrF Recall: 0.01\n",
      "\n",
      "Computing chrF score for task: HumanEval/67\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/68\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/69\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/70\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/71\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/72\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/73\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/74\n",
      "chrF F1-score: 0.13\n",
      "chrF F1-score (macro-averaged): 0.13\n",
      "chrF Precision: 0.13\n",
      "chrF Recall: 0.13\n",
      "\n",
      "Computing chrF score for task: HumanEval/75\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/76\n",
      "chrF F1-score: 0.24\n",
      "chrF F1-score (macro-averaged): 0.24\n",
      "chrF Precision: 0.24\n",
      "chrF Recall: 0.24\n",
      "\n",
      "Computing chrF score for task: HumanEval/77\n",
      "chrF F1-score: 0.12\n",
      "chrF F1-score (macro-averaged): 0.12\n",
      "chrF Precision: 0.12\n",
      "chrF Recall: 0.12\n",
      "\n",
      "Computing chrF score for task: HumanEval/78\n",
      "chrF F1-score: 0.01\n",
      "chrF F1-score (macro-averaged): 0.01\n",
      "chrF Precision: 0.01\n",
      "chrF Recall: 0.01\n",
      "\n",
      "Computing chrF score for task: HumanEval/79\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/80\n",
      "chrF F1-score: 0.15\n",
      "chrF F1-score (macro-averaged): 0.15\n",
      "chrF Precision: 0.15\n",
      "chrF Recall: 0.15\n",
      "\n",
      "Computing chrF score for task: HumanEval/81\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "\n",
      "Computing chrF score for task: HumanEval/82\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/83\n",
      "chrF F1-score: 0.37\n",
      "chrF F1-score (macro-averaged): 0.37\n",
      "chrF Precision: 0.37\n",
      "chrF Recall: 0.37\n",
      "\n",
      "Computing chrF score for task: HumanEval/84\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/85\n",
      "chrF F1-score: 0.69\n",
      "chrF F1-score (macro-averaged): 0.69\n",
      "chrF Precision: 0.69\n",
      "chrF Recall: 0.69\n",
      "\n",
      "Computing chrF score for task: HumanEval/86\n",
      "chrF F1-score: 0.18\n",
      "chrF F1-score (macro-averaged): 0.18\n",
      "chrF Precision: 0.18\n",
      "chrF Recall: 0.18\n",
      "\n",
      "Computing chrF score for task: HumanEval/87\n",
      "chrF F1-score: 0.24\n",
      "chrF F1-score (macro-averaged): 0.24\n",
      "chrF Precision: 0.24\n",
      "chrF Recall: 0.24\n",
      "\n",
      "Computing chrF score for task: HumanEval/88\n",
      "chrF F1-score: 0.12\n",
      "chrF F1-score (macro-averaged): 0.12\n",
      "chrF Precision: 0.12\n",
      "chrF Recall: 0.12\n",
      "\n",
      "Computing chrF score for task: HumanEval/89\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/90\n",
      "chrF F1-score: 0.21\n",
      "chrF F1-score (macro-averaged): 0.21\n",
      "chrF Precision: 0.21\n",
      "chrF Recall: 0.21\n",
      "\n",
      "Computing chrF score for task: HumanEval/91\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/92\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/93\n",
      "chrF F1-score: 0.11\n",
      "chrF F1-score (macro-averaged): 0.11\n",
      "chrF Precision: 0.11\n",
      "chrF Recall: 0.11\n",
      "\n",
      "Computing chrF score for task: HumanEval/94\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/95\n",
      "chrF F1-score: 0.19\n",
      "chrF F1-score (macro-averaged): 0.19\n",
      "chrF Precision: 0.19\n",
      "chrF Recall: 0.19\n",
      "\n",
      "Computing chrF score for task: HumanEval/96\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/97\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/98\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/99\n",
      "chrF F1-score: 0.11\n",
      "chrF F1-score (macro-averaged): 0.11\n",
      "chrF Precision: 0.11\n",
      "chrF Recall: 0.11\n",
      "\n",
      "Computing chrF score for task: HumanEval/100\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/101\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "\n",
      "Computing chrF score for task: HumanEval/102\n",
      "chrF F1-score: 0.21\n",
      "chrF F1-score (macro-averaged): 0.21\n",
      "chrF Precision: 0.21\n",
      "chrF Recall: 0.21\n",
      "\n",
      "Computing chrF score for task: HumanEval/103\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/104\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/105\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/106\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "\n",
      "Computing chrF score for task: HumanEval/107\n",
      "chrF F1-score: 0.13\n",
      "chrF F1-score (macro-averaged): 0.13\n",
      "chrF Precision: 0.13\n",
      "chrF Recall: 0.13\n",
      "\n",
      "Computing chrF score for task: HumanEval/108\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/109\n",
      "chrF F1-score: 0.16\n",
      "chrF F1-score (macro-averaged): 0.16\n",
      "chrF Precision: 0.16\n",
      "chrF Recall: 0.16\n",
      "\n",
      "Computing chrF score for task: HumanEval/110\n",
      "chrF F1-score: 0.12\n",
      "chrF F1-score (macro-averaged): 0.12\n",
      "chrF Precision: 0.12\n",
      "chrF Recall: 0.12\n",
      "\n",
      "Computing chrF score for task: HumanEval/111\n",
      "chrF F1-score: 0.11\n",
      "chrF F1-score (macro-averaged): 0.11\n",
      "chrF Precision: 0.11\n",
      "chrF Recall: 0.11\n",
      "\n",
      "Computing chrF score for task: HumanEval/112\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/113\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/114\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/115\n",
      "chrF F1-score: 0.23\n",
      "chrF F1-score (macro-averaged): 0.23\n",
      "chrF Precision: 0.23\n",
      "chrF Recall: 0.23\n",
      "\n",
      "Computing chrF score for task: HumanEval/116\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/117\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/118\n",
      "chrF F1-score: 0.41\n",
      "chrF F1-score (macro-averaged): 0.41\n",
      "chrF Precision: 0.41\n",
      "chrF Recall: 0.41\n",
      "\n",
      "Computing chrF score for task: HumanEval/119\n",
      "chrF F1-score: 0.13\n",
      "chrF F1-score (macro-averaged): 0.13\n",
      "chrF Precision: 0.13\n",
      "chrF Recall: 0.13\n",
      "\n",
      "Computing chrF score for task: HumanEval/120\n",
      "chrF F1-score: 0.12\n",
      "chrF F1-score (macro-averaged): 0.12\n",
      "chrF Precision: 0.12\n",
      "chrF Recall: 0.12\n",
      "\n",
      "Computing chrF score for task: HumanEval/121\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/122\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/123\n",
      "chrF F1-score: 0.16\n",
      "chrF F1-score (macro-averaged): 0.16\n",
      "chrF Precision: 0.16\n",
      "chrF Recall: 0.16\n",
      "\n",
      "Computing chrF score for task: HumanEval/124\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/125\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/126\n",
      "chrF F1-score: 0.17\n",
      "chrF F1-score (macro-averaged): 0.17\n",
      "chrF Precision: 0.17\n",
      "chrF Recall: 0.17\n",
      "\n",
      "Computing chrF score for task: HumanEval/127\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/128\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/129\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/130\n",
      "chrF F1-score: 0.29\n",
      "chrF F1-score (macro-averaged): 0.29\n",
      "chrF Precision: 0.29\n",
      "chrF Recall: 0.29\n",
      "\n",
      "Computing chrF score for task: HumanEval/131\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/132\n",
      "chrF F1-score: 0.11\n",
      "chrF F1-score (macro-averaged): 0.11\n",
      "chrF Precision: 0.11\n",
      "chrF Recall: 0.11\n",
      "\n",
      "Computing chrF score for task: HumanEval/133\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/134\n",
      "chrF F1-score: 0.12\n",
      "chrF F1-score (macro-averaged): 0.12\n",
      "chrF Precision: 0.12\n",
      "chrF Recall: 0.12\n",
      "\n",
      "Computing chrF score for task: HumanEval/135\n",
      "chrF F1-score: 0.10\n",
      "chrF F1-score (macro-averaged): 0.10\n",
      "chrF Precision: 0.10\n",
      "chrF Recall: 0.10\n",
      "\n",
      "Computing chrF score for task: HumanEval/136\n",
      "chrF F1-score: 0.13\n",
      "chrF F1-score (macro-averaged): 0.13\n",
      "chrF Precision: 0.13\n",
      "chrF Recall: 0.13\n",
      "\n",
      "Computing chrF score for task: HumanEval/137\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/138\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/139\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/140\n",
      "chrF F1-score: 0.29\n",
      "chrF F1-score (macro-averaged): 0.29\n",
      "chrF Precision: 0.29\n",
      "chrF Recall: 0.29\n",
      "\n",
      "Computing chrF score for task: HumanEval/141\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/142\n",
      "chrF F1-score: 0.79\n",
      "chrF F1-score (macro-averaged): 0.79\n",
      "chrF Precision: 0.79\n",
      "chrF Recall: 0.79\n",
      "\n",
      "Computing chrF score for task: HumanEval/143\n",
      "chrF F1-score: 0.02\n",
      "chrF F1-score (macro-averaged): 0.02\n",
      "chrF Precision: 0.02\n",
      "chrF Recall: 0.02\n",
      "\n",
      "Computing chrF score for task: HumanEval/144\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/145\n",
      "chrF F1-score: 0.14\n",
      "chrF F1-score (macro-averaged): 0.14\n",
      "chrF Precision: 0.14\n",
      "chrF Recall: 0.14\n",
      "\n",
      "Computing chrF score for task: HumanEval/146\n",
      "chrF F1-score: 0.22\n",
      "chrF F1-score (macro-averaged): 0.22\n",
      "chrF Precision: 0.22\n",
      "chrF Recall: 0.22\n",
      "\n",
      "Computing chrF score for task: HumanEval/147\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/148\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/149\n",
      "chrF F1-score: 0.15\n",
      "chrF F1-score (macro-averaged): 0.15\n",
      "chrF Precision: 0.15\n",
      "chrF Recall: 0.15\n",
      "\n",
      "Computing chrF score for task: HumanEval/150\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/151\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/152\n",
      "chrF F1-score: 0.04\n",
      "chrF F1-score (macro-averaged): 0.04\n",
      "chrF Precision: 0.04\n",
      "chrF Recall: 0.04\n",
      "\n",
      "Computing chrF score for task: HumanEval/153\n",
      "chrF F1-score: 0.07\n",
      "chrF F1-score (macro-averaged): 0.07\n",
      "chrF Precision: 0.07\n",
      "chrF Recall: 0.07\n",
      "\n",
      "Computing chrF score for task: HumanEval/154\n",
      "chrF F1-score: 0.17\n",
      "chrF F1-score (macro-averaged): 0.17\n",
      "chrF Precision: 0.17\n",
      "chrF Recall: 0.17\n",
      "\n",
      "Computing chrF score for task: HumanEval/155\n",
      "chrF F1-score: 0.06\n",
      "chrF F1-score (macro-averaged): 0.06\n",
      "chrF Precision: 0.06\n",
      "chrF Recall: 0.06\n",
      "\n",
      "Computing chrF score for task: HumanEval/156\n",
      "chrF F1-score: 0.05\n",
      "chrF F1-score (macro-averaged): 0.05\n",
      "chrF Precision: 0.05\n",
      "chrF Recall: 0.05\n",
      "\n",
      "Computing chrF score for task: HumanEval/157\n",
      "chrF F1-score: 0.00\n",
      "chrF F1-score (macro-averaged): 0.00\n",
      "chrF Precision: 0.00\n",
      "chrF Recall: 0.00\n",
      "\n",
      "Computing chrF score for task: HumanEval/158\n",
      "chrF F1-score: 0.08\n",
      "chrF F1-score (macro-averaged): 0.08\n",
      "chrF Precision: 0.08\n",
      "chrF Recall: 0.08\n",
      "\n",
      "Computing chrF score for task: HumanEval/159\n",
      "chrF F1-score: 0.57\n",
      "chrF F1-score (macro-averaged): 0.57\n",
      "chrF Precision: 0.57\n",
      "chrF Recall: 0.57\n",
      "\n",
      "Computing chrF score for task: HumanEval/160\n",
      "chrF F1-score: 0.46\n",
      "chrF F1-score (macro-averaged): 0.46\n",
      "chrF Precision: 0.46\n",
      "chrF Recall: 0.46\n",
      "\n",
      "Computing chrF score for task: HumanEval/161\n",
      "chrF F1-score: 0.16\n",
      "chrF F1-score (macro-averaged): 0.16\n",
      "chrF Precision: 0.16\n",
      "chrF Recall: 0.16\n",
      "\n",
      "Computing chrF score for task: HumanEval/162\n",
      "chrF F1-score: 0.61\n",
      "chrF F1-score (macro-averaged): 0.61\n",
      "chrF Precision: 0.61\n",
      "chrF Recall: 0.61\n",
      "\n",
      "Computing chrF score for task: HumanEval/163\n",
      "chrF F1-score: 0.09\n",
      "chrF F1-score (macro-averaged): 0.09\n",
      "chrF Precision: 0.09\n",
      "chrF Recall: 0.09\n",
      "Metric CHRF computation complete.\n",
      "Normalised BLEU scores saved to autometrics/Data/normalized_scores\\bleu_scores_gemini-1.5.csv\n",
      "Normalised ROUGE scores saved to autometrics/Data/normalized_scores\\rouge_scores_gemini-1.5.csv\n",
      "Normalised CodeBERTScores saved to autometrics/Data/normalized_scores\\cbs_gemini-1.5.csv\n",
      "Normalised chrF scores saved to autometrics/Data/normalized_scores\\chrf_gemini-1.5.csv\n",
      "BLEU scores saved to autometrics/Data/metric_scores\\bleu_scores_gemini-1.5.csv\n",
      "ROUGE scores saved to autometrics/Data/metric_scores\\rouge_scores_gemini-1.5.csv\n",
      "CodeBERTScores saved to autometrics/Data/metric_scores\\cbs_gemini-1.5.csv\n",
      "chrF scores saved to autometrics/Data/metric_scores\\chrf_gemini-1.5.csv\n"
     ]
    }
   ],
   "source": [
    "from autometrics.utils.AutoMetrics import *\n",
    "\n",
    "# computes automatic metrics for all models \n",
    "for model_output in os.listdir(\"autometrics/Data/model_outputs\"):\n",
    "    ams = AutoMetrics(model_output)\n",
    "    ams.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge metrics with LLM and human evaluations (Gemini-1.5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bec580fe60c36d4"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "scores_df = pd.read_csv('Evaluation/llm_human_evaluation results.csv')\n",
    "normalized_bleu_df = pd.read_csv('autometrics/Data/normalized_scores/bleu_scores_gemini-1.5.csv')\n",
    "normalized_rouge_df = pd.read_csv('autometrics/Data/normalized_scores/rouge_scores_gemini-1.5.csv')\n",
    "normalized_cbs_df = pd.read_csv('autometrics/Data/normalized_scores/cbs_gemini-1.5.csv')\n",
    "normalized_chrf_df = pd.read_csv('autometrics/Data/normalized_scores/chrf_gemini-1.5.csv')\n",
    "scores_df['BLEU'] = normalized_bleu_df['BLEU Score'].round(2)\n",
    "scores_df['ROUGE Precision'] = normalized_rouge_df['ROUGE-L Precision'].round(2)\n",
    "scores_df['ROUGE Recall'] = normalized_rouge_df['ROUGE-L Recall'].round(2)\n",
    "scores_df['ROUGE F1-score'] = normalized_rouge_df['ROUGE-L F1-score'].round(2)\n",
    "scores_df['CodeBERTScore Precision'] = normalized_cbs_df['CodeBERTScore Precision'].round(2)\n",
    "scores_df['CodeBERTScore Recall'] = normalized_cbs_df['CodeBERTScore Recall'].round(2)\n",
    "scores_df['CodeBERTScore F1-score'] = normalized_cbs_df['CodeBERTScore F1-score'].round(2)\n",
    "scores_df['CodeBERTScore F3-score'] = normalized_cbs_df['CodeBERTScore F3-score'].round(2)\n",
    "scores_df['chrF F1-score'] = normalized_chrf_df['chrF F1-score'].round(2)\n",
    "\n",
    "scores_df = scores_df.loc[:, ~scores_df.columns.str.contains('^Unnamed')]\n",
    "scores_df.to_csv('Evaluation/merged_evaluation_results_gemini-1.5.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-20T13:15:50.222318400Z",
     "start_time": "2025-01-20T13:15:50.167276500Z"
    }
   },
   "id": "21fbd6a184158921"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEMO Autometrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7eac47d62fcedefd"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "         score  human_score  BLEU  ROUGE Precision  ROUGE Recall  \\\ntask_id                                                            \n0         4.35         5.00  2.08             3.31          3.31   \n1         4.30         5.00  1.19             2.73          2.73   \n2         5.00         5.00  5.00             5.00          5.00   \n3         5.00         5.00  3.41             4.20          4.20   \n4         5.00         5.00  1.56             2.02          2.02   \n5         3.95         5.00  1.43             3.60          3.60   \n6         4.45         5.00  1.35             2.52          2.52   \n7         4.45         4.85  1.13             1.86          1.86   \n8         5.00         4.85  1.85             2.09          2.09   \n9         4.60         5.00  1.05             1.52          1.52   \n\n         ROUGE F1-score  CodeBERTScore Precision  CodeBERTScore Recall  \\\ntask_id                                                                  \n0                  3.35                     4.62                  4.55   \n1                  3.00                     4.33                  4.47   \n2                  5.00                     5.00                  5.00   \n3                  4.20                     4.92                  4.92   \n4                  2.52                     4.01                  4.62   \n5                  3.54                     4.71                  4.80   \n6                  2.49                     4.41                  4.33   \n7                  2.04                     4.18                  4.25   \n8                  2.50                     4.05                  4.40   \n9                  1.76                     3.76                  3.91   \n\n         CodeBERTScore F1-score  CodeBERTScore F3-score  chrF F1-score  \ntask_id                                                                 \n0                          4.59                    4.56           1.88  \n1                          4.40                    4.46           1.37  \n2                          5.00                    5.00           5.00  \n3                          4.92                    4.92           3.94  \n4                          4.29                    4.55           1.62  \n5                          4.75                    4.79           3.47  \n6                          4.37                    4.34           1.31  \n7                          4.22                    4.25           1.11  \n8                          4.21                    4.36           1.38  \n9                          3.83                    3.89           1.28  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>human_score</th>\n      <th>BLEU</th>\n      <th>ROUGE Precision</th>\n      <th>ROUGE Recall</th>\n      <th>ROUGE F1-score</th>\n      <th>CodeBERTScore Precision</th>\n      <th>CodeBERTScore Recall</th>\n      <th>CodeBERTScore F1-score</th>\n      <th>CodeBERTScore F3-score</th>\n      <th>chrF F1-score</th>\n    </tr>\n    <tr>\n      <th>task_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.35</td>\n      <td>5.00</td>\n      <td>2.08</td>\n      <td>3.31</td>\n      <td>3.31</td>\n      <td>3.35</td>\n      <td>4.62</td>\n      <td>4.55</td>\n      <td>4.59</td>\n      <td>4.56</td>\n      <td>1.88</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.30</td>\n      <td>5.00</td>\n      <td>1.19</td>\n      <td>2.73</td>\n      <td>2.73</td>\n      <td>3.00</td>\n      <td>4.33</td>\n      <td>4.47</td>\n      <td>4.40</td>\n      <td>4.46</td>\n      <td>1.37</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>5.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>3.41</td>\n      <td>4.20</td>\n      <td>4.20</td>\n      <td>4.20</td>\n      <td>4.92</td>\n      <td>4.92</td>\n      <td>4.92</td>\n      <td>4.92</td>\n      <td>3.94</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.00</td>\n      <td>5.00</td>\n      <td>1.56</td>\n      <td>2.02</td>\n      <td>2.02</td>\n      <td>2.52</td>\n      <td>4.01</td>\n      <td>4.62</td>\n      <td>4.29</td>\n      <td>4.55</td>\n      <td>1.62</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.95</td>\n      <td>5.00</td>\n      <td>1.43</td>\n      <td>3.60</td>\n      <td>3.60</td>\n      <td>3.54</td>\n      <td>4.71</td>\n      <td>4.80</td>\n      <td>4.75</td>\n      <td>4.79</td>\n      <td>3.47</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.45</td>\n      <td>5.00</td>\n      <td>1.35</td>\n      <td>2.52</td>\n      <td>2.52</td>\n      <td>2.49</td>\n      <td>4.41</td>\n      <td>4.33</td>\n      <td>4.37</td>\n      <td>4.34</td>\n      <td>1.31</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4.45</td>\n      <td>4.85</td>\n      <td>1.13</td>\n      <td>1.86</td>\n      <td>1.86</td>\n      <td>2.04</td>\n      <td>4.18</td>\n      <td>4.25</td>\n      <td>4.22</td>\n      <td>4.25</td>\n      <td>1.11</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5.00</td>\n      <td>4.85</td>\n      <td>1.85</td>\n      <td>2.09</td>\n      <td>2.09</td>\n      <td>2.50</td>\n      <td>4.05</td>\n      <td>4.40</td>\n      <td>4.21</td>\n      <td>4.36</td>\n      <td>1.38</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4.60</td>\n      <td>5.00</td>\n      <td>1.05</td>\n      <td>1.52</td>\n      <td>1.52</td>\n      <td>1.76</td>\n      <td>3.76</td>\n      <td>3.91</td>\n      <td>3.83</td>\n      <td>3.89</td>\n      <td>1.28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df = pd.read_csv('Evaluation/merged_evaluation_results_gemini-1.5.csv', index_col='task_id')\n",
    "metric_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-19T23:50:27.818096700Z",
     "start_time": "2025-01-19T23:50:27.775265900Z"
    }
   },
   "id": "f94fd54e8a77a024"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f6638cd04727739d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
